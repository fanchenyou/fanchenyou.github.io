<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Research Publications | Chenyou Fan</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Research Publications" />
<meta name="author" content="Chenyou Fan (Ph.D.)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Associate Professor of School of Artificial Intelligence, South China Normal University." />
<meta property="og:description" content="Associate Professor of School of Artificial Intelligence, South China Normal University." />
<link rel="canonical" href="http://localhost:4000/publications/" />
<meta property="og:url" content="http://localhost:4000/publications/" />
<meta property="og:site_name" content="Chenyou Fan" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Research Publications" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Chenyou Fan (Ph.D.)"},"description":"Associate Professor of School of Artificial Intelligence, South China Normal University.","headline":"Research Publications","url":"http://localhost:4000/publications/"}</script>
<!-- End Jekyll SEO tag -->


<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Chenyou Fan" />





<!-- Google Fonts -->
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open%20Sans|Roboto|Roboto%20Slab|Inconsolata|Dancing%20Script|Noto%20Sans%20SC|Noto%20Sans%20TC|Noto%20Serif%20SC|Noto%20Serif%20TC|Ma%20Shan%20Zheng">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/skin.css">

<!-- Begin selecting skin -->

<!-- End selecting skin -->

<script async src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>




  </head>

  <body>
    <div class="site-container">
      <header class="site-header">
        <div class="wrapper">
  <script>
    function clickSidebarButton() {
      const elem = document.getElementById("site-sidebar")
      if (elem.style.display == "none" || elem.style.display == "") {
        elem.style.display = "block";
      } else {
        elem.style.display = "none";
      }
    }
  </script>
  <a class="site-sidebar-button" onclick="clickSidebarButton()"><i class="far fa-user"></i>
  </a>

  <a class="site-title" rel="author" href="/">Chenyou Fan</a>

  
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger" title="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <ul class="trigger">
              <li><a class="" href="/">About</a></li>
            
              <li><a class="current-page" href="/publications/">Publications</a></li>
            
              <li><a class="" href="/projects/">Projects</a></li>
            
              <li><a class="" href="/presentations/">Presentations</a></li>
            
              <li><a class="" href="/teaching/">Teaching</a></li>
            
              <li class="dropdown" href="#">
                <a href="javascript:void(0)" class="dropbtn">More</a>
                <div class="dropdown-content">
                    <a class="" href="/datasets/">Datasets</a>
                    <a class="" href="/patents/">Patents</a>
                </div>
              </li>
            </ul>
    </nav>
  
</div>

      </header>
      
      <div class="site-body wrapper">
        <aside class="site-sidebar" id="site-sidebar">
          
            <div class="sidebar-section"><img src="/FCY.jpg" class="author-avatar u-photo align-center" alt="Chenyou Fan (Ph.D.)">
  </div>

<div class="sidebar-section">
  <ul class="contact-list">
    <li>
        <i class="sidebar-icon fas fa-at"></i>
        <span class="contact-info p-name">Chenyou Fan (Ph.D.)</span>
      </li>
    <li>
        <i class="sidebar-icon fas fa-envelope"></i>
        <a class="contact-info u-email" href="mailto:fanchenyou-at-gmail.com">fanchenyou-at-gmail.com</a>
      </li>
    
  </ul>
</div>
	

<div class="sidebar-section">
    <ul class="social-icons">
      <li>
          <a class="social-icon" href="https://github.com/fanchenyou"><i class="fab fa-github fa-2x" title="GitHub"></i></a>
        </li>
        <li>
	        <a href="https://www.scholat.com/fanchenyou">
  				<img src="/scholat.png" style="margin-top: -15px;" width="30" height="32">
			</a>
	    </li>
    </ul>
  </div>

          
        </aside>
        <main class="site-main" id="site-main" aria-label="Content" tabindex="1">
          <article class="post">

  <header class="post-header">
    <h1 class="post-title">Research Publications</h1>
  </header>

  <div class="post-content">
    <p>My research topics include first-person videos, image captioning, video question answering, federated learning and time series analysis. An up-to-date list is available on <a href="https://scholar.google.com/citations?user=FRu9MHcAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a>.</p>

<h2 id="selected-publicaitons">Selected Publicaitons</h2>
<ul>
  <li>
    <p><strong>Chenyou Fan</strong>, Junjie Hu, Jianwei Huang. <strong><em>“Few-Shot Multi-Agent Perception with Ranking-Based Feature Learning.”</em></strong> IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023. (TPAMI-23). <a href="https://ieeexplore.ieee.org/document/10149393" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p>Xiangyang Liu, Tianqi Pang, <strong>Chenyou Fan</strong>. <strong><em>“Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering.”</em></strong> International Conference on Knowledge Science, Engineering and Management (KSEM-23). <a href="https://arxiv.org/abs/2304.13911" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p>Tianqi Pang, Kehui Tan, <strong>Chenyou Fan</strong>. <strong><em>“Carbon Price Forecasting with Quantile Regression and Feature Selection.”</em></strong> International Conference on Data Mining and Knowledge Discovery (DMKD-23). <a href="https://arxiv.org/abs/2305.03224" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p>Heng-yang Lu, <strong>Chenyou Fan</strong>, others. <strong><em>“Where to Attack: A Dynamic Locator Model for Backdoor Attack in Text Classifications.”</em></strong> International Conference on Computational Linguistics (COLING-22).</p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Junjie Hu, Jianwei Huang. <strong><em>“Private Semi-Supervised Federated Learning.”</em></strong> 31st International Joint Conference on Artificial Intelligence (IJCAI’22, 15% acceptance rate). <a href="https://www.ijcai.org/proceedings/2022/279" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Junjie Hu, Jianwei Huang. <strong><em>“Few-Shot Multi-Agent Perception.”</em></strong> 29th ACM International Conference on Multimedia 2021 (ACM MM’21, 27.9% acceptance rate) <a href="./docs/fs_map_1.pdf" target="_blank">[pdf]</a> <a href="./docs/mm21_poster.pdf" target="_blank">[poster]</a> <a href="https://github.com/fanchenyou/fs-map-project" target="_blank">[code]</a></p>
  </li>
  <li>
    <p>Tianyi Lin, <strong>Chenyou Fan</strong> (co-first), Nhat Ho, Marco Cuturi, Michael I. Jordan. <strong><em>“Projection Robust Wasserstein Distance and Riemannian Optimization.”</em></strong> Conference on Neural Information Processing Systems (NeurIPS’20, spotlight, 20% acceptance rate, 3% spotlight rate) <a href="https://arxiv.org/abs/2006.07458" target="_blank">[pdf]</a> <a href="https://github.com/fanchenyou/PRW" target="_blank">[code]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Ping Liu. <strong><em>“Federated Generative Adversarial Learning.”</em></strong> Chinese Conference on Pattern Recognition and Computer Vision (PRCV’20). <a href="https://arxiv.org/abs/2005.03793" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Heng Huang. <strong><em>“Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering.”</em></strong> IEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR’19, 25.2% acceptance rate) <a href="https://arxiv.org/pdf/1904.04357.pdf" target="_blank">[pdf]</a> <a href="https://github.com/fanchenyou/HME-VideoQA" target="_blank">[code]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Heng Huang. <strong><em>“Multi-Horizon Time Series Forecasting with Temporal Attention Learning.”</em></strong> SIGKDD Conference on Knowledge Discovery and Data Mining 2019 (KDD’19, 20% acceptance rate). <a href="https://dl.acm.org/doi/10.1145/3292500.3330662" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Zehua Zhang, David J. Crandall. <strong><em>“DeepDiary: Lifelogging Image Captioning and Summarization.”</em></strong> 2018. Journal of Visual Communication and Image Representation. <a href="https://www.sciencedirect.com/science/article/abs/pii/S1047320318301032" target="_blank">[link]</a></p>
  </li>
  <li>
    <p>Mingze Xu, <strong>Chenyou Fan</strong>, Yuchen Wang, Michael S. Ryoo, David J. Crandall. <strong><em>“Joint Person Segmentation and Identification in Synchronized First-and Third-person Videos.”</em></strong> European Conference on Computer Vision 2018 (ECCV’18). <a href="http://vision.soic.indiana.edu/firstthird-eccv2018/" target="_blank">[project]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Jangwon Lee, Mingze Xu, K.K. Singh, Y.J. Lee, David J. Crandall, Michael S. Ryoo. <strong><em>“Identifying first-person camera wearers in third-person videos.”</em></strong> IEEE Conference on Computer Vision and Pattern Recognition 2017 (CVPR’17, 29.0% acceptance rate). <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Fan_Identifying_First-Person_Camera_CVPR_2017_paper.pdf" target="_blank">[pdf]</a> <a href="http://vision.soic.indiana.edu/identifying-1st-3rd/" target="_blank">[data &amp; project page]</a></p>
  </li>
  <li>
    <p>AJ Piergiovanni, <strong>Chenyou Fan</strong>, and Michael S. Ryoo. <strong><em>“Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters.”</em></strong> the 31st AAAI Conference on Artificial Intelligence (AAAI), February 2017. <a href="http://arxiv.org/abs/1605.08140" target="_blank">[pdf]</a></p>
  </li>
</ul>

<h2 id="tutorials">Tutorials</h2>
<ul>
  <li><strong>Chenyou Fan</strong>. <strong><em>“Survey of Convolutional Neural Network.”</em></strong> <a href="https://fanchenyou.github.io/docs/cnn_survey.pdf" target="_blank">[pdf]</a></li>
</ul>

<h2 id="more-research-collaboration-work">More Research Collaboration work</h2>

<ul>
  <li>
    <p>Junjie Hu, <strong>Chenyou Fan</strong>, Hualie Jiang, Xiyue Guo, Yuan Gao, Xiangyong Lu, Tin Lun Lam. <strong><em>“Boosting LightWeight Depth Estimation Via Knowledge Distillation.”</em></strong> International Conference on Knowledge Science, Engineering and Management (KSEM-23). <a href="https://arxiv.org/abs/2105.06143" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p>Junjie Hu, Chenyu Bao, Mete Ozay, <strong>Chenyou Fan</strong>, Qing Gao, Honghai Liu, Tin Lun Lam. <strong><em>“Deep Depth Completion from Extremely Sparse Data: A Survey.”</em></strong> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). 2022-12. <a href="https://arxiv.org/abs/2205.05335" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Jianwei Huang. <strong><em>“Federated Few-Shot Learning with Adversarial Learning.”</em></strong> 19th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt ‘21). <a href="https://arxiv.org/abs/2104.00365" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p>Hengyang Lu, <strong>Chenyou Fan</strong>. <strong><em>“Few-shot COVID-19 Rumor Detection for Online Social Media.”</em></strong> PeerJ Computer Science. <a href="https://peerj.com/articles/cs-688/" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p>Tianyi Lin, <strong>Chenyou Fan</strong>, Mengdi Wang, M.I.Jordan. “Improved Sample Complexity for Stochastic Compositional Variance Reduced Gradient.” American Control Conference 2020 (ACC’20). <a href="https://arxiv.org/abs/1806.00458" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p>Mingze Xu, <strong>Chenyou Fan</strong>, John Paden, Geoffrey Fox, and David J. Crandall. <strong><em>“Multi-Task Spatiotemporal Neural Networks for Structured Surface Reconstruction.”</em></strong> IEEE Winter Conference on Applications of Computer Vision 2018 (WACV’18). <a href="https://arxiv.org/pdf/1801.03986.pdf" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>. <strong><em>“EgoVQA - An Egocentric Video Question Answering Benchmark Dataset.”</em></strong> International Workshop on Egocentric Perception, Interaction and Computing (EPIC@ICCV), Octorber 2019. <a href="https://openaccess.thecvf.com/content_ICCVW_2019/html/EPIC/Fan_EgoVQA_-_An_Egocentric_Video_Question_Answering_Benchmark_Dataset_ICCVW_2019_paper.html" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong>, Jangwon Lee and Michael S. Ryoo. <strong><em>“Forecasting Hand and Object Locations in Future Frames.”</em></strong> European Conference Workshop on Anticipating Human Behavior (AHB@ECCV), August 2018. <a href="https://arxiv.org/abs/1705.07328" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p><strong>Chenyou Fan</strong> and David J. Crandall. <strong><em>“Deepdiary: Automatically Captioning Lifelogging Image Streams.”</em></strong> European Conference Workshop on Egocentric Perception, Interaction, and Computing (EPIC@ECCV), October 2016. <a href="http://vision.soic.indiana.edu/projects/deepdiary-automatically-captioning-lifelogging-image-streams/" target="_blank">[pdf]</a></p>
  </li>
</ul>


<div class="taxonomies-wrapper">
  <ul class="taxonomies"></ul>
</div>

<script>
  function backToTop() {
    const main = document.getElementById("site-main");
    main.scrollTop = 0;
  }
</script>

  </div>

</article>

          <footer class="site-footer">
            <div class="footer-col-wrapper">

  <div class="footer-col">
    <div class="copyright">
      
      
      
      
      <p>Copyright © 2017&nbsp;-&nbsp;2023 Chenyou Fan (Ph.D.); All rights reserved.</p>
      
    </div>
    <p>
      Powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://github.com/ngzhio/jekyll-theme-hamilton">Hamilton</a>
    </p>
  </div>

  <div class="footer-col">
    <p>Associate Professor of School of Artificial Intelligence, South China Normal University.</p>
  </div>
</div>

          </footer>
        </main>
      </div>
    </div>
  </body>

</html>

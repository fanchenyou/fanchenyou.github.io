<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters | Chenyou Fan</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this paper, we introduce the concept of learning latent super-events from activity videos, and present how it benefits activity detection in continuous videos. We define a super-event as a set of multiple events occurring together in videos with a particular temporal organization; it is the opposite concept of sub-events. Real-world videos contain multiple activities and are rarely segmented (e.g., surveillance videos), and learning latent super-events allows the model to capture how the events are temporally related in videos. We design temporal structure filters that enable the model to focus on particular sub-intervals of the videos, and use them together with a soft attention mechanism to learn representations of latent super-events. Super-event representations are combined with per-frame or per-segment CNNs to provide frame-level annotations. Our approach is designed to be fully differentiable, enabling end-to-end learning of latent super-event representations jointly with the activity detector using them. Our experiments with multiple public video datasets confirm that the proposed concept of latent super-event learning significantly benefits activity detection, advancing the state-of-the-arts." />
<meta property="og:description" content="In this paper, we introduce the concept of learning latent super-events from activity videos, and present how it benefits activity detection in continuous videos. We define a super-event as a set of multiple events occurring together in videos with a particular temporal organization; it is the opposite concept of sub-events. Real-world videos contain multiple activities and are rarely segmented (e.g., surveillance videos), and learning latent super-events allows the model to capture how the events are temporally related in videos. We design temporal structure filters that enable the model to focus on particular sub-intervals of the videos, and use them together with a soft attention mechanism to learn representations of latent super-events. Super-event representations are combined with per-frame or per-segment CNNs to provide frame-level annotations. Our approach is designed to be fully differentiable, enabling end-to-end learning of latent super-event representations jointly with the activity detector using them. Our experiments with multiple public video datasets confirm that the proposed concept of latent super-event learning significantly benefits activity detection, advancing the state-of-the-arts." />
<link rel="canonical" href="http://localhost:4000/2017/12/05/Learning-Latent-Super-Events-to-Detect-Multiple-Activities-in-Videos.html" />
<meta property="og:url" content="http://localhost:4000/2017/12/05/Learning-Latent-Super-Events-to-Detect-Multiple-Activities-in-Videos.html" />
<meta property="og:site_name" content="Chenyou Fan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-12-05T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2017-12-05T00:00:00+08:00","datePublished":"2017-12-05T00:00:00+08:00","description":"In this paper, we introduce the concept of learning latent super-events from activity videos, and present how it benefits activity detection in continuous videos. We define a super-event as a set of multiple events occurring together in videos with a particular temporal organization; it is the opposite concept of sub-events. Real-world videos contain multiple activities and are rarely segmented (e.g., surveillance videos), and learning latent super-events allows the model to capture how the events are temporally related in videos. We design temporal structure filters that enable the model to focus on particular sub-intervals of the videos, and use them together with a soft attention mechanism to learn representations of latent super-events. Super-event representations are combined with per-frame or per-segment CNNs to provide frame-level annotations. Our approach is designed to be fully differentiable, enabling end-to-end learning of latent super-event representations jointly with the activity detector using them. Our experiments with multiple public video datasets confirm that the proposed concept of latent super-event learning significantly benefits activity detection, advancing the state-of-the-arts.","headline":"Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/12/05/Learning-Latent-Super-Events-to-Detect-Multiple-Activities-in-Videos.html"},"url":"http://localhost:4000/2017/12/05/Learning-Latent-Super-Events-to-Detect-Multiple-Activities-in-Videos.html"}</script>
<!-- End Jekyll SEO tag -->


<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Chenyou Fan" />





<!-- Google Fonts -->
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open%20Sans|Roboto|Roboto%20Slab|Inconsolata|Dancing%20Script|Noto%20Sans%20SC|Noto%20Sans%20TC|Noto%20Serif%20SC|Noto%20Serif%20TC|Ma%20Shan%20Zheng">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/skin.css">

<!-- Begin selecting skin -->

<!-- End selecting skin -->

<script async src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>




  </head>

  <body>
    <div class="site-container">
      <header class="site-header">
        <div class="wrapper">
  <script>
    function clickSidebarButton() {
      const elem = document.getElementById("site-sidebar")
      if (elem.style.display == "none" || elem.style.display == "") {
        elem.style.display = "block";
      } else {
        elem.style.display = "none";
      }
    }
  </script>
  <a class="site-sidebar-button" onclick="clickSidebarButton()"><i class="far fa-user"></i>
  </a>

  <a class="site-title" rel="author" href="/">Chenyou Fan</a>

  
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger" title="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <ul class="trigger">
              <li><a class="" href="/">About</a></li>
            
              <li><a class="" href="/publications/">Publications</a></li>
            
              <li><a class="" href="/projects/">Projects</a></li>
            
              <li><a class="" href="/presentations/">Presentations</a></li>
            
              <li><a class="" href="/teaching/">Teaching</a></li>
            
              <li class="dropdown" href="#">
                <a href="javascript:void(0)" class="dropbtn">More</a>
                <div class="dropdown-content">
                    <a class="" href="/datasets/">Datasets</a>
                    <a class="" href="/patents/">Patents</a>
                </div>
              </li>
            </ul>
    </nav>
  
</div>

      </header>
      
      <div class="site-body wrapper">
        <aside class="site-sidebar" id="site-sidebar">
          
            <div class="sidebar-section"><img src="/FCY.jpg" class="author-avatar u-photo align-center" alt="Chenyou Fan (Ph.D.)">
  </div>

<div class="sidebar-section">
  <ul class="contact-list">
    <li>
        <i class="sidebar-icon fas fa-at"></i>
        <span class="contact-info p-name">Chenyou Fan (Ph.D.)</span>
      </li>
    <li>
        <i class="sidebar-icon fas fa-envelope"></i>
        <a class="contact-info u-email" href="mailto:fanchenyou-at-gmail.com">fanchenyou-at-gmail.com</a>
      </li>
    
  </ul>
</div>
	

<div class="sidebar-section">
    <ul class="social-icons">
      <li>
          <a class="social-icon" href="https://github.com/fanchenyou"><i class="fab fa-github fa-2x" title="GitHub"></i></a>
        </li>
        <li>
	        <a href="https://www.scholat.com/fanchenyou">
  				<img src="/scholat.png" style="margin-top: -15px;" width="30" height="32">
			</a>
	    </li>
    </ul>
  </div>

          
        </aside>
        <main class="site-main" id="site-main" aria-label="Content" tabindex="1">
          <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">

    <h1 class="post-title p-name" itemprop="name headline">Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters</h1>
    <p class="post-meta"><time class="dt-published" datetime="2017-12-05T00:00:00+08:00" itemprop="datePublished">
        Dec 5, 2017
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">AJ Piergiovanni</span></span>, 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chenyou Fan</span></span>, 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">and Michael S. Ryoo</span></span></p>

  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In this paper, we introduce the concept of learning latent super-events from activity videos, and present how it benefits activity detection in continuous videos. We define a super-event as a set of multiple events occurring together in videos with a particular temporal organization; it is the opposite concept of sub-events. Real-world videos contain multiple activities and are rarely segmented (e.g., surveillance videos), and learning latent super-events allows the model to capture how the events are temporally related in videos. We design temporal structure filters that enable the model to focus on particular sub-intervals of the videos, and use them together with a soft attention mechanism to learn representations of latent super-events. Super-event representations are combined with per-frame or per-segment CNNs to provide frame-level annotations. Our approach is designed to be fully differentiable, enabling end-to-end learning of latent super-event representations jointly with the activity detector using them. Our experiments with multiple public video datasets confirm that the proposed concept of latent super-event learning significantly benefits activity detection, advancing the state-of-the-arts.</p>

<h6 id="the-31st-aaai-conference-on-artificial-intelligence-aaai-february-2017">the 31st AAAI Conference on Artificial Intelligence (AAAI), February 2017</h6>

<p><a href="https://arxiv.org/abs/1712.01938" target="_blank">for more information</a><br /></p>

  </div>

  <footer class="post-footer">
    

    

    <nav class="post-pagination" role="navigation">
      
        <a class="post-previous" href="/2017/04/20/Identifying-First-person-Camera-Wearers-in-Third-person-Videos.html">
          <h4 class="post-pagination-label">Prev</h4>
          <span class="post-pagination-title">
            <i class="fas fa-arrow-left"></i> Identifying First-person Camera Wearers in Third-person Videos

          </span>
        </a>
      

      
        <a class="post-next" href="/2018/01/11/Multi-Task-Spatiotemporal-Neural-Networks-for-Structured-Surface-Reconstruction.html">
          <h4 class="post-pagination-label">Next</h4>
          <span class="post-pagination-title">
            Multi-Task Spatiotemporal Neural Networks for Structured Surface Reconstruction
 <i class="fas fa-arrow-right"></i>
          </span>
        </a>
      
    </nav>
  </footer>

  
  
</article>

          <footer class="site-footer">
            <div class="footer-col-wrapper">

  <div class="footer-col">
    <div class="copyright">
      
      
      
      
      <p>Copyright © 2017&nbsp;-&nbsp;2023 Chenyou Fan (Ph.D.); All rights reserved.</p>
      
    </div>
    <p>
      Powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://github.com/ngzhio/jekyll-theme-hamilton">Hamilton</a>
    </p>
  </div>

  <div class="footer-col">
    <p>Associate Professor of School of Artificial Intelligence, South China Normal University.</p>
  </div>
</div>

          </footer>
        </main>
      </div>
    </div>
  </body>

</html>

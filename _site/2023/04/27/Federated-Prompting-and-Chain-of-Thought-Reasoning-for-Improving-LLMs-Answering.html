<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering | Chenyou Fan</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We investigate how to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). Our study focuses on a typical situations where users ask similar queries that involve identical mathematical reasoning steps and problem-solving procedures. Due to the unsatisfactory accuracy of LLMs’ zero-shot prompting with standalone questions, we propose to improve the distributed synonymous questions using Self-Consistency (SC) and Chain-of-Thought (CoT) techniques. Specifically, we first retrieve synonymous questions from a crowd-sourced database and create a federated question pool. We call these federated synonymous questions with the same or different parameters SP-questions or DP-questions, respectively. We refer to our methods as Fed-SP-SC and Fed-DP-CoT, which can generate significantly more accurate answers for all user queries without requiring sophisticated model-tuning. Through extensive experiments, we demonstrate that our proposed methods can significantly enhance question accuracy by fully exploring the synonymous nature of the questions and the consistency of the answers." />
<meta property="og:description" content="We investigate how to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). Our study focuses on a typical situations where users ask similar queries that involve identical mathematical reasoning steps and problem-solving procedures. Due to the unsatisfactory accuracy of LLMs’ zero-shot prompting with standalone questions, we propose to improve the distributed synonymous questions using Self-Consistency (SC) and Chain-of-Thought (CoT) techniques. Specifically, we first retrieve synonymous questions from a crowd-sourced database and create a federated question pool. We call these federated synonymous questions with the same or different parameters SP-questions or DP-questions, respectively. We refer to our methods as Fed-SP-SC and Fed-DP-CoT, which can generate significantly more accurate answers for all user queries without requiring sophisticated model-tuning. Through extensive experiments, we demonstrate that our proposed methods can significantly enhance question accuracy by fully exploring the synonymous nature of the questions and the consistency of the answers." />
<link rel="canonical" href="http://localhost:4000/2023/04/27/Federated-Prompting-and-Chain-of-Thought-Reasoning-for-Improving-LLMs-Answering.html" />
<meta property="og:url" content="http://localhost:4000/2023/04/27/Federated-Prompting-and-Chain-of-Thought-Reasoning-for-Improving-LLMs-Answering.html" />
<meta property="og:site_name" content="Chenyou Fan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-04-27T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-27T00:00:00+08:00","datePublished":"2023-04-27T00:00:00+08:00","description":"We investigate how to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). Our study focuses on a typical situations where users ask similar queries that involve identical mathematical reasoning steps and problem-solving procedures. Due to the unsatisfactory accuracy of LLMs’ zero-shot prompting with standalone questions, we propose to improve the distributed synonymous questions using Self-Consistency (SC) and Chain-of-Thought (CoT) techniques. Specifically, we first retrieve synonymous questions from a crowd-sourced database and create a federated question pool. We call these federated synonymous questions with the same or different parameters SP-questions or DP-questions, respectively. We refer to our methods as Fed-SP-SC and Fed-DP-CoT, which can generate significantly more accurate answers for all user queries without requiring sophisticated model-tuning. Through extensive experiments, we demonstrate that our proposed methods can significantly enhance question accuracy by fully exploring the synonymous nature of the questions and the consistency of the answers.","headline":"Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2023/04/27/Federated-Prompting-and-Chain-of-Thought-Reasoning-for-Improving-LLMs-Answering.html"},"url":"http://localhost:4000/2023/04/27/Federated-Prompting-and-Chain-of-Thought-Reasoning-for-Improving-LLMs-Answering.html"}</script>
<!-- End Jekyll SEO tag -->


<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Chenyou Fan" />





<!-- Google Fonts -->
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open%20Sans|Roboto|Roboto%20Slab|Inconsolata|Dancing%20Script|Noto%20Sans%20SC|Noto%20Sans%20TC|Noto%20Serif%20SC|Noto%20Serif%20TC|Ma%20Shan%20Zheng">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/skin.css">

<!-- Begin selecting skin -->

<!-- End selecting skin -->

<script async src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>




  </head>

  <body>
    <div class="site-container">
      <header class="site-header">
        <div class="wrapper">
  <script>
    function clickSidebarButton() {
      const elem = document.getElementById("site-sidebar")
      if (elem.style.display == "none" || elem.style.display == "") {
        elem.style.display = "block";
      } else {
        elem.style.display = "none";
      }
    }
  </script>
  <a class="site-sidebar-button" onclick="clickSidebarButton()"><i class="far fa-user"></i>
  </a>

  <a class="site-title" rel="author" href="/">Chenyou Fan</a>

  
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger" title="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <ul class="trigger">
              <li><a class="" href="/">About</a></li>
            
              <li><a class="" href="/publications/">Publications</a></li>
            
              <li><a class="" href="/projects/">Projects</a></li>
            
              <li><a class="" href="/presentations/">Presentations</a></li>
            
              <li><a class="" href="/teaching/">Teaching</a></li>
            
              <li class="dropdown" href="#">
                <a href="javascript:void(0)" class="dropbtn">More</a>
                <div class="dropdown-content">
                    <a class="" href="/datasets/">Datasets</a>
                    <a class="" href="/patents/">Patents</a>
                </div>
              </li>
            </ul>
    </nav>
  
</div>

      </header>
      
      <div class="site-body wrapper">
        <aside class="site-sidebar" id="site-sidebar">
          
            <div class="sidebar-section"><img src="/FCY.jpg" class="author-avatar u-photo align-center" alt="Chenyou Fan (Ph.D.)">
  </div>

<div class="sidebar-section">
  <ul class="contact-list">
    <li>
        <i class="sidebar-icon fas fa-at"></i>
        <span class="contact-info p-name">Chenyou Fan (Ph.D.)</span>
      </li>
    <li>
        <i class="sidebar-icon fas fa-envelope"></i>
        <a class="contact-info u-email" href="mailto:fanchenyou-at-gmail.com">fanchenyou-at-gmail.com</a>
      </li>
    
  </ul>
</div>
	

<div class="sidebar-section">
    <ul class="social-icons">
      <li>
          <a class="social-icon" href="https://github.com/fanchenyou"><i class="fab fa-github fa-2x" title="GitHub"></i></a>
        </li>
        <li>
	        <a href="https://www.scholat.com/fanchenyou">
  				<img src="/scholat.png" style="margin-top: -15px;" width="30" height="32">
			</a>
	    </li>
    </ul>
  </div>

          
        </aside>
        <main class="site-main" id="site-main" aria-label="Content" tabindex="1">
          <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">

    <h1 class="post-title p-name" itemprop="name headline">Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering</h1>
    <p class="post-meta"><time class="dt-published" datetime="2023-04-27T00:00:00+08:00" itemprop="datePublished">
        Apr 27, 2023
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Xiangyang Liu</span></span>, 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Tianqi Pang</span></span>, 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chenyou Fan</span></span></p>

  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>We investigate how to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). Our study focuses on a typical situations where users ask similar queries that involve identical mathematical reasoning steps and problem-solving procedures. Due to the unsatisfactory accuracy of LLMs’ zero-shot prompting with standalone questions, we propose to improve the distributed synonymous questions using Self-Consistency (SC) and Chain-of-Thought (CoT) techniques. Specifically, we first retrieve synonymous questions from a crowd-sourced database and create a federated question pool. We call these federated synonymous questions with the same or different parameters SP-questions or DP-questions, respectively. We refer to our methods as Fed-SP-SC and Fed-DP-CoT, which can generate significantly more accurate answers for all user queries without requiring sophisticated model-tuning. Through extensive experiments, we demonstrate that our proposed methods can significantly enhance question accuracy by fully exploring the synonymous nature of the questions and the consistency of the answers.</p>

<h6 id="international-conference-on-knowledge-science-engineering-and-management-ksem-23">International Conference on Knowledge Science, Engineering and Management (KSEM-23)</h6>

<p><a href="https://arxiv.org/abs/2304.13911#:~:text=Federated%20Prompting%20and%20Chain-of-Thought%20Reasoning%20for%20Improving%20LLMs,distributed%20users%20using%20cloud-based%20Large%20Language%20Models%20%28LLMs%29." target="_blank">for more information</a></p>

  </div>

  <footer class="post-footer">
    

    

    <nav class="post-pagination" role="navigation">
      
        <a class="post-previous" href="/2022/10/18/where-to-attack-a-dynamic-locator-model-for-backdoor-attack-in-text-classifications.html">
          <h4 class="post-pagination-label">Prev</h4>
          <span class="post-pagination-title">
            <i class="fas fa-arrow-left"></i> Where to Attack：A Dynamic Locator Model for Backdoor Attack in Text Classifications

          </span>
        </a>
      

      
        <a class="post-next" href="/2023/05/05/Carbon-Price-Forecasting-with-Quantile-Regression-and-Feature-Selection.html">
          <h4 class="post-pagination-label">Next</h4>
          <span class="post-pagination-title">
            Carbon Price Forecasting with Quantile Regression and Feature Selection
 <i class="fas fa-arrow-right"></i>
          </span>
        </a>
      
    </nav>
  </footer>

  
  
</article>

          <footer class="site-footer">
            <div class="footer-col-wrapper">

  <div class="footer-col">
    <div class="copyright">
      
      
      
      
      <p>Copyright © 2017&nbsp;-&nbsp;2023 Chenyou Fan (Ph.D.); All rights reserved.</p>
      
    </div>
    <p>
      Powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://github.com/ngzhio/jekyll-theme-hamilton">Hamilton</a>
    </p>
  </div>

  <div class="footer-col">
    <p>Associate Professor of School of Artificial Intelligence, South China Normal University.</p>
  </div>
</div>

          </footer>
        </main>
      </div>
    </div>
  </body>

</html>
